{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Practical Work\n",
    "\n",
    "## Data Science and Engineering\n",
    "\n",
    "### DESIGN OF AN IMAGE FILTER FUNCTION, PARALLELIZABLE AND SCALABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full name:** ANDRES ORTIZ \n",
    "    \n",
    "**NIA** : **1004261219**\n",
    "\n",
    "This code was developed with **RAUL MALLO ALONSO; NIA: 100429745**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we simply import the necessary dependencies to execute the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.sharedctypes import Array\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cProfile\n",
    "import ctypes\n",
    "import functions as my "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration of class attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we declare and assign the attributes that will be used in the subsequent methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_IMAGE1=\"lena.png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1= np.array(Image.open(F_IMAGE1))\n",
    "image2= np.array(Image.open(F_IMAGE1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first filter is impulse response filter (the image output must be equals to the original one).\n",
    "* The second filter is an edge filter, first order in x axis,  \n",
    "* The third filter is an edge filter, first order in y axis,\n",
    "* the fourth filter is an edge filter, second order, bi-directional\n",
    "* the fifth filter is a blur gausian filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1=np.array([\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,1,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]\n",
    "])\n",
    "filter2=np.array([0.5, 0 , -0.5])\n",
    "filter3=np.array([[0.5],[0],[0.5]])\n",
    "\n",
    "filter4=np.array([\n",
    "    [1,0,-1],\n",
    "    [2,0,-2],\n",
    "    [1,0,-1]\n",
    "])\n",
    "filter5=np.array([\n",
    "    [0.00078633,0.00655965,0.01330373,0.00655965,0.00078633],\n",
    "    [0.00655965,0.05472157,0.11098164,0.05472157,0.00655965],\n",
    "    [0.01330373,0.11098164,0.22508352,0.11098164,0.01330373],\n",
    "    [0.00655965,0.05472157,0.11098164,0.05472157,0.00655965],\n",
    "    [0.00078633,0.00655965,0.01330373,0.00655965,0.00078633]\n",
    "])\n",
    "filter6=np.array([0.5, 0 ,0,0, -0.5])\n",
    "filter7=np.array([[0.5],[0],[0],[0],[0.5]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the size of each data buffer and allocate memory to each shared space where our filtered image data will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buffer1_size=image1.shape[0]*image1.shape[1]*image1.shape[2]\n",
    "shared_space1= Array(ctypes.c_byte,data_buffer1_size)\n",
    "\n",
    "data_buffer2_size=image2.shape[0]*image2.shape[1]*image2.shape[2]\n",
    "shared_space2= Array(ctypes.c_byte,data_buffer2_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration of auxiliary functions\n",
    "The following function converts an array into a numpy array so that we can assign the shared memory spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonumpyarray(mp_arr):\n",
    "    \"\"\"\n",
    "    This function creates a numpy array of uint8\n",
    "    :param mp_arr: the array to be transformed\n",
    "    \"\"\"\n",
    "    # mp_array is a shared memory array with a lock\n",
    "    return np.frombuffer(mp_arr.get_obj(), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter the images, we create two processes with a different filter each. \n",
    "The Process object represents an activity that is run in a separate process. The start() function starts the process's activity, while the join() functions waits until the process whose join() method is called terminates the execution of the target function. (In this case, image_filter() is the target function)\n",
    "\n",
    "These processes will split the number of cores available in half so that half of the resources work on process 1 and half work on process 2. These processes will each execute the image_filter() function which will then assign a thread pool to the task of computing the filter values. \n",
    "Once both processes are complete, the function finishes its execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filters_execution(p_image, p_filter1, p_filter2, p_numprocessors, p_shared_space1,\n",
    "                      p_shared_space2):\n",
    "    \"\"\"\n",
    "    This functions executes the two processes that will use the thread pools to run the fulters\n",
    "\n",
    "    :param p_image: the image to be filtered\n",
    "    :param p_filter1: the first filter\n",
    "    :param p_filter2: the seconds filter\n",
    "    :param p_numprocessors: the number of processors to be used\n",
    "    :param p_shared_space1: the first shared memory space\n",
    "    :param p_shared_space2: the second shared memory space\n",
    "    \"\"\"\n",
    "    # creates a lock to handle memory access\n",
    "    lock = mp.Lock()\n",
    "\n",
    "    # define and start the processes\n",
    "    p1 = mp.Process(target=my.image_filter, args=(p_image, p_filter1, p_numprocessors,\n",
    "                                                  p_shared_space1))\n",
    "    p2 = mp.Process(target=my.image_filter, args=(p_image, p_filter2, p_numprocessors,\n",
    "                                                  p_shared_space2))\n",
    "\n",
    "    # start the processes\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    # wait until the processes have ended\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we divide the number of cpus in two and ensure that the value is an integer. This is the amount of processors that will be destined to each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numprocessors= int(mp.cpu_count()/2)\n",
    "print(numprocessors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we execute the main filter function.filters_execution(image1,filter3,filter2,numprocessors,shared_space1,shared_space2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_execution(image1,filter3,filter2,numprocessors,shared_space1,shared_space2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "In this last step, we take the filtered images that are stored in the multiprocessing vectors (filtered_image1_VECTOR) and (filtered_image2_VECTOR), convert them to numpy array, and reshape them to match the shape of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_image1=tonumpyarray(shared_space1).reshape(image1.shape)\n",
    "filtered_image2=tonumpyarray(shared_space2).reshape(image2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we display the images with the selected filters applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(1, 2, 1)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(filtered_image1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Filter1\")\n",
    "\n",
    "# Adds a subplot at the 2nd position\n",
    "fig.add_subplot(1, 2, 2)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(filtered_image2)\n",
    "plt.axis('off')\n",
    "plt.title(\"Filter2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of thread pools in this project allows us to take advantage of the concurrency offered by multicore architectures on modern computers. In software, when we execute an algorithm or a program using a single thread, we are leaving valuable resources unused. By using thread pools, we can maximize the amount of parallel tasks that are executed because a thread can be reused if a thread in a thread pool completes its execution and a new thread is created to replace a thread that is terminated. However, in this particalr case we are applying two filters on a single image simultaneously. In order to achieve this, we created two processes that divide the CPU's resources in two and store the results in a shared memory location. Now, the way the general algorithm works is great but it is limited since we are simply using Python's multiprocessing library. We would most likely see an increase in performance if we used the Ray framework. \n",
    "This framework is a faster and simpler framework for building and running distributed applications. Thw following article highlights the tradeoffs between using Ray vs using Python's multiprocessing. <https://towardsdatascience.com/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1>.\n",
    "\n",
    "Secondly, in this practical work we are processing images with the cores available on our machine. However, this is a huge bottleneck because CPUs on consumer machines don't usually come with a large amount of available cores. If we could process these images using a GPU, we would see a huge increase in performance since the number of threads avaiable on a GPU often  hundreds of times greater. GPUs use the SIMT (single instruction, multiple threads) programming model, so it is highly parallelizable. Additionally, GPUs have shared memory that simultaneously available to each core of one multiprocessor, is a lot faster than the bandwidth of of the L1 cache of a CPU\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
